{"ast":null,"code":"'use strict';\n\nvar TransformStream = require('stream').Transform,\n  DevNullStream = require('./dev_null_stream'),\n  inherits = require('util').inherits,\n  Tokenizer = require('../tokenizer'),\n  LocationInfoTokenizerMixin = require('../extensions/location_info/tokenizer_mixin'),\n  ParserFeedbackSimulator = require('./parser_feedback_simulator'),\n  mergeOptions = require('../utils/merge_options');\nvar DEFAULT_OPTIONS = {\n  locationInfo: false\n};\nvar SAXParser = module.exports = function (options) {\n  TransformStream.call(this);\n  this.options = mergeOptions(DEFAULT_OPTIONS, options);\n  this.tokenizer = new Tokenizer(options);\n  if (this.options.locationInfo) new LocationInfoTokenizerMixin(this.tokenizer);\n  this.parserFeedbackSimulator = new ParserFeedbackSimulator(this.tokenizer);\n  this.pendingText = null;\n  this.currentTokenLocation = void 0;\n  this.lastChunkWritten = false;\n  this.stopped = false;\n\n  // NOTE: always pipe stream to the /dev/null stream to avoid\n  // `highWaterMark` hit even if we don't have consumers.\n  // (see: https://github.com/inikulin/parse5/issues/97#issuecomment-171940774)\n  this.pipe(new DevNullStream());\n};\ninherits(SAXParser, TransformStream);\n\n//TransformStream implementation\nSAXParser.prototype._transform = function (chunk, encoding, callback) {\n  if (!this.stopped) {\n    this.tokenizer.write(chunk.toString('utf8'), this.lastChunkWritten);\n    this._runParsingLoop();\n  }\n  this.push(chunk);\n  callback();\n};\nSAXParser.prototype._flush = function (callback) {\n  callback();\n};\nSAXParser.prototype.end = function (chunk, encoding, callback) {\n  this.lastChunkWritten = true;\n  TransformStream.prototype.end.call(this, chunk, encoding, callback);\n};\nSAXParser.prototype.stop = function () {\n  this.stopped = true;\n};\n\n//Internals\nSAXParser.prototype._runParsingLoop = function () {\n  do {\n    var token = this.parserFeedbackSimulator.getNextToken();\n    if (token.type === Tokenizer.HIBERNATION_TOKEN) break;\n    if (token.type === Tokenizer.CHARACTER_TOKEN || token.type === Tokenizer.WHITESPACE_CHARACTER_TOKEN || token.type === Tokenizer.NULL_CHARACTER_TOKEN) {\n      if (this.options.locationInfo) {\n        if (this.pendingText === null) this.currentTokenLocation = token.location;else this.currentTokenLocation.endOffset = token.location.endOffset;\n      }\n      this.pendingText = (this.pendingText || '') + token.chars;\n    } else {\n      this._emitPendingText();\n      this._handleToken(token);\n    }\n  } while (!this.stopped && token.type !== Tokenizer.EOF_TOKEN);\n};\nSAXParser.prototype._handleToken = function (token) {\n  if (this.options.locationInfo) this.currentTokenLocation = token.location;\n  if (token.type === Tokenizer.START_TAG_TOKEN) this.emit('startTag', token.tagName, token.attrs, token.selfClosing, this.currentTokenLocation);else if (token.type === Tokenizer.END_TAG_TOKEN) this.emit('endTag', token.tagName, this.currentTokenLocation);else if (token.type === Tokenizer.COMMENT_TOKEN) this.emit('comment', token.data, this.currentTokenLocation);else if (token.type === Tokenizer.DOCTYPE_TOKEN) this.emit('doctype', token.name, token.publicId, token.systemId, this.currentTokenLocation);\n};\nSAXParser.prototype._emitPendingText = function () {\n  if (this.pendingText !== null) {\n    this.emit('text', this.pendingText, this.currentTokenLocation);\n    this.pendingText = null;\n  }\n};","map":{"version":3,"names":["TransformStream","require","Transform","DevNullStream","inherits","Tokenizer","LocationInfoTokenizerMixin","ParserFeedbackSimulator","mergeOptions","DEFAULT_OPTIONS","locationInfo","SAXParser","module","exports","options","call","tokenizer","parserFeedbackSimulator","pendingText","currentTokenLocation","lastChunkWritten","stopped","pipe","prototype","_transform","chunk","encoding","callback","write","toString","_runParsingLoop","push","_flush","end","stop","token","getNextToken","type","HIBERNATION_TOKEN","CHARACTER_TOKEN","WHITESPACE_CHARACTER_TOKEN","NULL_CHARACTER_TOKEN","location","endOffset","chars","_emitPendingText","_handleToken","EOF_TOKEN","START_TAG_TOKEN","emit","tagName","attrs","selfClosing","END_TAG_TOKEN","COMMENT_TOKEN","data","DOCTYPE_TOKEN","name","publicId","systemId"],"sources":["C:/Users/Sator/WebProjects/kanjiMnemonics/create-react-app/node_modules/react-render-html/node_modules/parse5/lib/sax/index.js"],"sourcesContent":["'use strict';\n\nvar TransformStream = require('stream').Transform,\n    DevNullStream = require('./dev_null_stream'),\n    inherits = require('util').inherits,\n    Tokenizer = require('../tokenizer'),\n    LocationInfoTokenizerMixin = require('../extensions/location_info/tokenizer_mixin'),\n    ParserFeedbackSimulator = require('./parser_feedback_simulator'),\n    mergeOptions = require('../utils/merge_options');\n\nvar DEFAULT_OPTIONS = {\n    locationInfo: false\n};\n\nvar SAXParser = module.exports = function (options) {\n    TransformStream.call(this);\n\n    this.options = mergeOptions(DEFAULT_OPTIONS, options);\n\n    this.tokenizer = new Tokenizer(options);\n\n    if (this.options.locationInfo)\n        new LocationInfoTokenizerMixin(this.tokenizer);\n\n    this.parserFeedbackSimulator = new ParserFeedbackSimulator(this.tokenizer);\n\n    this.pendingText = null;\n    this.currentTokenLocation = void 0;\n\n    this.lastChunkWritten = false;\n    this.stopped = false;\n\n    // NOTE: always pipe stream to the /dev/null stream to avoid\n    // `highWaterMark` hit even if we don't have consumers.\n    // (see: https://github.com/inikulin/parse5/issues/97#issuecomment-171940774)\n    this.pipe(new DevNullStream());\n};\n\ninherits(SAXParser, TransformStream);\n\n//TransformStream implementation\nSAXParser.prototype._transform = function (chunk, encoding, callback) {\n    if (!this.stopped) {\n        this.tokenizer.write(chunk.toString('utf8'), this.lastChunkWritten);\n        this._runParsingLoop();\n    }\n\n    this.push(chunk);\n\n    callback();\n};\n\nSAXParser.prototype._flush = function (callback) {\n    callback();\n};\n\nSAXParser.prototype.end = function (chunk, encoding, callback) {\n    this.lastChunkWritten = true;\n    TransformStream.prototype.end.call(this, chunk, encoding, callback);\n};\n\nSAXParser.prototype.stop = function () {\n    this.stopped = true;\n};\n\n//Internals\nSAXParser.prototype._runParsingLoop = function () {\n    do {\n        var token = this.parserFeedbackSimulator.getNextToken();\n\n        if (token.type === Tokenizer.HIBERNATION_TOKEN)\n            break;\n\n        if (token.type === Tokenizer.CHARACTER_TOKEN ||\n            token.type === Tokenizer.WHITESPACE_CHARACTER_TOKEN ||\n            token.type === Tokenizer.NULL_CHARACTER_TOKEN) {\n\n            if (this.options.locationInfo) {\n                if (this.pendingText === null)\n                    this.currentTokenLocation = token.location;\n\n                else\n                    this.currentTokenLocation.endOffset = token.location.endOffset;\n            }\n\n            this.pendingText = (this.pendingText || '') + token.chars;\n        }\n\n        else {\n            this._emitPendingText();\n            this._handleToken(token);\n        }\n    } while (!this.stopped && token.type !== Tokenizer.EOF_TOKEN);\n};\n\nSAXParser.prototype._handleToken = function (token) {\n    if (this.options.locationInfo)\n        this.currentTokenLocation = token.location;\n\n    if (token.type === Tokenizer.START_TAG_TOKEN)\n        this.emit('startTag', token.tagName, token.attrs, token.selfClosing, this.currentTokenLocation);\n\n    else if (token.type === Tokenizer.END_TAG_TOKEN)\n        this.emit('endTag', token.tagName, this.currentTokenLocation);\n\n    else if (token.type === Tokenizer.COMMENT_TOKEN)\n        this.emit('comment', token.data, this.currentTokenLocation);\n\n    else if (token.type === Tokenizer.DOCTYPE_TOKEN)\n        this.emit('doctype', token.name, token.publicId, token.systemId, this.currentTokenLocation);\n};\n\nSAXParser.prototype._emitPendingText = function () {\n    if (this.pendingText !== null) {\n        this.emit('text', this.pendingText, this.currentTokenLocation);\n        this.pendingText = null;\n    }\n};\n"],"mappings":"AAAA,YAAY;;AAEZ,IAAIA,eAAe,GAAGC,OAAO,CAAC,QAAQ,CAAC,CAACC,SAAS;EAC7CC,aAAa,GAAGF,OAAO,CAAC,mBAAmB,CAAC;EAC5CG,QAAQ,GAAGH,OAAO,CAAC,MAAM,CAAC,CAACG,QAAQ;EACnCC,SAAS,GAAGJ,OAAO,CAAC,cAAc,CAAC;EACnCK,0BAA0B,GAAGL,OAAO,CAAC,6CAA6C,CAAC;EACnFM,uBAAuB,GAAGN,OAAO,CAAC,6BAA6B,CAAC;EAChEO,YAAY,GAAGP,OAAO,CAAC,wBAAwB,CAAC;AAEpD,IAAIQ,eAAe,GAAG;EAClBC,YAAY,EAAE;AAClB,CAAC;AAED,IAAIC,SAAS,GAAGC,MAAM,CAACC,OAAO,GAAG,UAAUC,OAAO,EAAE;EAChDd,eAAe,CAACe,IAAI,CAAC,IAAI,CAAC;EAE1B,IAAI,CAACD,OAAO,GAAGN,YAAY,CAACC,eAAe,EAAEK,OAAO,CAAC;EAErD,IAAI,CAACE,SAAS,GAAG,IAAIX,SAAS,CAACS,OAAO,CAAC;EAEvC,IAAI,IAAI,CAACA,OAAO,CAACJ,YAAY,EACzB,IAAIJ,0BAA0B,CAAC,IAAI,CAACU,SAAS,CAAC;EAElD,IAAI,CAACC,uBAAuB,GAAG,IAAIV,uBAAuB,CAAC,IAAI,CAACS,SAAS,CAAC;EAE1E,IAAI,CAACE,WAAW,GAAG,IAAI;EACvB,IAAI,CAACC,oBAAoB,GAAG,KAAK,CAAC;EAElC,IAAI,CAACC,gBAAgB,GAAG,KAAK;EAC7B,IAAI,CAACC,OAAO,GAAG,KAAK;;EAEpB;EACA;EACA;EACA,IAAI,CAACC,IAAI,CAAC,IAAInB,aAAa,CAAC,CAAC,CAAC;AAClC,CAAC;AAEDC,QAAQ,CAACO,SAAS,EAAEX,eAAe,CAAC;;AAEpC;AACAW,SAAS,CAACY,SAAS,CAACC,UAAU,GAAG,UAAUC,KAAK,EAAEC,QAAQ,EAAEC,QAAQ,EAAE;EAClE,IAAI,CAAC,IAAI,CAACN,OAAO,EAAE;IACf,IAAI,CAACL,SAAS,CAACY,KAAK,CAACH,KAAK,CAACI,QAAQ,CAAC,MAAM,CAAC,EAAE,IAAI,CAACT,gBAAgB,CAAC;IACnE,IAAI,CAACU,eAAe,CAAC,CAAC;EAC1B;EAEA,IAAI,CAACC,IAAI,CAACN,KAAK,CAAC;EAEhBE,QAAQ,CAAC,CAAC;AACd,CAAC;AAEDhB,SAAS,CAACY,SAAS,CAACS,MAAM,GAAG,UAAUL,QAAQ,EAAE;EAC7CA,QAAQ,CAAC,CAAC;AACd,CAAC;AAEDhB,SAAS,CAACY,SAAS,CAACU,GAAG,GAAG,UAAUR,KAAK,EAAEC,QAAQ,EAAEC,QAAQ,EAAE;EAC3D,IAAI,CAACP,gBAAgB,GAAG,IAAI;EAC5BpB,eAAe,CAACuB,SAAS,CAACU,GAAG,CAAClB,IAAI,CAAC,IAAI,EAAEU,KAAK,EAAEC,QAAQ,EAAEC,QAAQ,CAAC;AACvE,CAAC;AAEDhB,SAAS,CAACY,SAAS,CAACW,IAAI,GAAG,YAAY;EACnC,IAAI,CAACb,OAAO,GAAG,IAAI;AACvB,CAAC;;AAED;AACAV,SAAS,CAACY,SAAS,CAACO,eAAe,GAAG,YAAY;EAC9C,GAAG;IACC,IAAIK,KAAK,GAAG,IAAI,CAAClB,uBAAuB,CAACmB,YAAY,CAAC,CAAC;IAEvD,IAAID,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACiC,iBAAiB,EAC1C;IAEJ,IAAIH,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACkC,eAAe,IACxCJ,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACmC,0BAA0B,IACnDL,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACoC,oBAAoB,EAAE;MAE/C,IAAI,IAAI,CAAC3B,OAAO,CAACJ,YAAY,EAAE;QAC3B,IAAI,IAAI,CAACQ,WAAW,KAAK,IAAI,EACzB,IAAI,CAACC,oBAAoB,GAAGgB,KAAK,CAACO,QAAQ,CAAC,KAG3C,IAAI,CAACvB,oBAAoB,CAACwB,SAAS,GAAGR,KAAK,CAACO,QAAQ,CAACC,SAAS;MACtE;MAEA,IAAI,CAACzB,WAAW,GAAG,CAAC,IAAI,CAACA,WAAW,IAAI,EAAE,IAAIiB,KAAK,CAACS,KAAK;IAC7D,CAAC,MAEI;MACD,IAAI,CAACC,gBAAgB,CAAC,CAAC;MACvB,IAAI,CAACC,YAAY,CAACX,KAAK,CAAC;IAC5B;EACJ,CAAC,QAAQ,CAAC,IAAI,CAACd,OAAO,IAAIc,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAAC0C,SAAS;AAChE,CAAC;AAEDpC,SAAS,CAACY,SAAS,CAACuB,YAAY,GAAG,UAAUX,KAAK,EAAE;EAChD,IAAI,IAAI,CAACrB,OAAO,CAACJ,YAAY,EACzB,IAAI,CAACS,oBAAoB,GAAGgB,KAAK,CAACO,QAAQ;EAE9C,IAAIP,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAAC2C,eAAe,EACxC,IAAI,CAACC,IAAI,CAAC,UAAU,EAAEd,KAAK,CAACe,OAAO,EAAEf,KAAK,CAACgB,KAAK,EAAEhB,KAAK,CAACiB,WAAW,EAAE,IAAI,CAACjC,oBAAoB,CAAC,CAAC,KAE/F,IAAIgB,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACgD,aAAa,EAC3C,IAAI,CAACJ,IAAI,CAAC,QAAQ,EAAEd,KAAK,CAACe,OAAO,EAAE,IAAI,CAAC/B,oBAAoB,CAAC,CAAC,KAE7D,IAAIgB,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACiD,aAAa,EAC3C,IAAI,CAACL,IAAI,CAAC,SAAS,EAAEd,KAAK,CAACoB,IAAI,EAAE,IAAI,CAACpC,oBAAoB,CAAC,CAAC,KAE3D,IAAIgB,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACmD,aAAa,EAC3C,IAAI,CAACP,IAAI,CAAC,SAAS,EAAEd,KAAK,CAACsB,IAAI,EAAEtB,KAAK,CAACuB,QAAQ,EAAEvB,KAAK,CAACwB,QAAQ,EAAE,IAAI,CAACxC,oBAAoB,CAAC;AACnG,CAAC;AAEDR,SAAS,CAACY,SAAS,CAACsB,gBAAgB,GAAG,YAAY;EAC/C,IAAI,IAAI,CAAC3B,WAAW,KAAK,IAAI,EAAE;IAC3B,IAAI,CAAC+B,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC/B,WAAW,EAAE,IAAI,CAACC,oBAAoB,CAAC;IAC9D,IAAI,CAACD,WAAW,GAAG,IAAI;EAC3B;AACJ,CAAC"},"metadata":{},"sourceType":"script","externalDependencies":[]}